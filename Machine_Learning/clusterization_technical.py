import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

def carregar_dados(caminho_dataset="../DataSet/spotify_songs.csv"):
    """
    Carrega o dataset e seleciona features t√©cnicas de produ√ß√£o musical.
    
    Features selecionadas:
    - loudness: Intensidade/volume da m√∫sica (dB)
    - speechiness: Presen√ßa de palavras faladas (0-1)
    - instrumentalness: N√≠vel de conte√∫do instrumental (0-1)
    - liveness: Indicador de grava√ß√£o ao vivo (0-1)
    - duration_min: Dura√ß√£o da m√∫sica em minutos
    
    Esta combina√ß√£o agrupa m√∫sicas por caracter√≠sticas de produ√ß√£o,
    formato e contexto de performance.
    """
    if not os.path.exists(caminho_dataset):
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {caminho_dataset}")
    
    print("[*] Carregando dataset...")
    df = pd.read_csv(caminho_dataset)
    
    # Features t√©cnicas de produ√ß√£o
    features = ['loudness', 'speechiness', 'instrumentalness', 'liveness', 'duration_ms']
    df_features = df[features].copy()
    
    # Converter dura√ß√£o de ms para minutos (mais interpret√°vel)
    df_features['duration_min'] = df_features['duration_ms'] / 60000
    df_features = df_features.drop('duration_ms', axis=1)
    
    print(f"[+] Dataset carregado com {len(df)} registros.")
    print(f"[+] Features t√©cnicas selecionadas: loudness, speechiness, instrumentalness, liveness, duration_min")
    return df, df_features

def preprocessar_dados(df_features):
    """
    Normaliza os dados usando StandardScaler.
    Importante para features com escalas diferentes (ex: loudness em dB vs. propor√ß√µes 0-1).
    """
    print("\n[*] Padronizando dados...")
    scaler = StandardScaler()
    dados_normalizados = scaler.fit_transform(df_features)
    print("[+] Dados normalizados.")
    return dados_normalizados, scaler

def escolher_numero_clusters(dados_normalizados, max_clusters=10):
    """
    M√©todo do Cotovelo (Elbow Method) para determinar n√∫mero √≥timo de clusters.
    """
    print("\n[*] Calculando WCSS para o m√©todo do cotovelo...")
    wcss = []
    for i in range(1, max_clusters + 1):
        km = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)
        km.fit(dados_normalizados)
        wcss.append(km.inertia_)
        print(f"    K={i}: WCSS={km.inertia_:.2f}")
    
    plt.figure(figsize=(10,6))
    plt.plot(range(1, max_clusters + 1), wcss, marker='o', linewidth=2, markersize=8)
    plt.xlabel("N√∫mero de clusters", fontsize=12)
    plt.ylabel("WCSS (In√©rcia)", fontsize=12)
    plt.title("M√©todo do Cotovelo - Clusteriza√ß√£o T√©cnica\n(Features de Produ√ß√£o Musical)", fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.xticks(range(1, max_clusters + 1))
    plt.tight_layout()
    plt.show()

def aplicar_kmeans(dados_normalizados, n_clusters=4):
    """
    Aplica K-Means++ com n√∫mero definido de clusters.
    """
    print(f"\n[*] Aplicando K-Means++ com {n_clusters} clusters...")
    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42, n_init=10)
    clusters = kmeans.fit_predict(dados_normalizados)
    print("[+] K-Means++ conclu√≠do.")
    print(f"[+] Distribui√ß√£o dos clusters: {np.bincount(clusters)}")
    return clusters, kmeans

def analisar_clusters(df, df_features, clusters, kmeans, scaler):
    """
    Analisa e visualiza os clusters formados.
    """
    df_resultado = df.copy()
    df_resultado['cluster'] = clusters
    
    # Adicionar as features processadas ao dataframe de resultado
    for col in df_features.columns:
        df_resultado[col] = df_features[col].values
    
    features = df_features.columns.tolist()

    # M√©dias das features por cluster
    medias = df_resultado.groupby('cluster')[features].mean()
    print("\n" + "="*80)
    print("AN√ÅLISE DOS CLUSTERS - Caracter√≠sticas T√©cnicas de Produ√ß√£o")
    print("="*80)
    print("\nM√©dias das features por cluster:\n")
    print(medias.round(3))
    print("\n" + "="*80)
    
    # Interpreta√ß√£o dos clusters
    print("\nINTERPRETA√á√ÉO DOS CLUSTERS:\n")
    for cluster_id in range(len(medias)):
        print(f"\nüéµ CLUSTER {cluster_id}:")
        print(f"   - Loudness: {medias.loc[cluster_id, 'loudness']:.2f} dB")
        print(f"   - Speechiness: {medias.loc[cluster_id, 'speechiness']:.3f}")
        print(f"   - Instrumentalness: {medias.loc[cluster_id, 'instrumentalness']:.3f}")
        print(f"   - Liveness: {medias.loc[cluster_id, 'liveness']:.3f}")
        print(f"   - Duration: {medias.loc[cluster_id, 'duration_min']:.2f} min")
        
        # Classifica√ß√£o autom√°tica do tipo
        if medias.loc[cluster_id, 'speechiness'] > 0.33:
            tipo = "üé§ FALADO (Rap/Hip-Hop/Podcast)"
        elif medias.loc[cluster_id, 'instrumentalness'] > 0.5:
            tipo = "üéπ INSTRUMENTAL"
        elif medias.loc[cluster_id, 'liveness'] > 0.3:
            tipo = "üé∏ AO VIVO"
        else:
            tipo = "üéß EST√öDIO (Produ√ß√£o Profissional)"
        
        print(f"   ‚Üí Tipo: {tipo}")
    
    print("\n" + "="*80)

    # Visualiza√ß√µes
    criar_visualizacoes(df_features, clusters, kmeans, features, scaler)

    return df_resultado, medias

def criar_visualizacoes(df_features, clusters, kmeans, features, scaler):
    """
    Cria m√∫ltiplas visualiza√ß√µes dos clusters.
    """
    # Plot 1: Speechiness vs Instrumentalness (mostra tipo de conte√∫do)
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    
    # Subplot 1: Speechiness vs Instrumentalness
    ax1 = axes[0, 0]
    scatter1 = ax1.scatter(
        df_features['speechiness'],
        df_features['instrumentalness'],
        c=clusters,
        cmap='viridis',
        alpha=0.6,
        s=20
    )
    centros_originais = scaler.inverse_transform(kmeans.cluster_centers_)
    ax1.scatter(
        centros_originais[:, features.index('speechiness')],
        centros_originais[:, features.index('instrumentalness')],
        c='red',
        s=300,
        alpha=0.9,
        marker='*',
        edgecolors='black',
        linewidths=2,
        label='Centr√≥ides'
    )
    ax1.set_xlabel('Speechiness (Conte√∫do Falado)', fontsize=11)
    ax1.set_ylabel('Instrumentalness (Instrumental)', fontsize=11)
    ax1.set_title('Tipo de Conte√∫do Musical', fontsize=12, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter1, ax=ax1, label='Cluster')
    
    # Subplot 2: Loudness vs Liveness (mostra contexto de produ√ß√£o)
    ax2 = axes[0, 1]
    scatter2 = ax2.scatter(
        df_features['loudness'],
        df_features['liveness'],
        c=clusters,
        cmap='viridis',
        alpha=0.6,
        s=20
    )
    ax2.scatter(
        centros_originais[:, features.index('loudness')],
        centros_originais[:, features.index('liveness')],
        c='red',
        s=300,
        alpha=0.9,
        marker='*',
        edgecolors='black',
        linewidths=2,
        label='Centr√≥ides'
    )
    ax2.set_xlabel('Loudness (Volume/dB)', fontsize=11)
    ax2.set_ylabel('Liveness (Grava√ß√£o ao Vivo)', fontsize=11)
    ax2.set_title('Contexto de Produ√ß√£o', fontsize=12, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    plt.colorbar(scatter2, ax=ax2, label='Cluster')
    
    # Subplot 3: Duration vs Loudness (mostra formato)
    ax3 = axes[1, 0]
    scatter3 = ax3.scatter(
        df_features['duration_min'],
        df_features['loudness'],
        c=clusters,
        cmap='viridis',
        alpha=0.6,
        s=20
    )
    ax3.scatter(
        centros_originais[:, features.index('duration_min')],
        centros_originais[:, features.index('loudness')],
        c='red',
        s=300,
        alpha=0.9,
        marker='*',
        edgecolors='black',
        linewidths=2,
        label='Centr√≥ides'
    )
    ax3.set_xlabel('Dura√ß√£o (minutos)', fontsize=11)
    ax3.set_ylabel('Loudness (Volume/dB)', fontsize=11)
    ax3.set_title('Formato e Intensidade', fontsize=12, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    plt.colorbar(scatter3, ax=ax3, label='Cluster')
    
    # Subplot 4: Distribui√ß√£o dos clusters
    ax4 = axes[1, 1]
    contagens = np.bincount(clusters)
    cores = plt.cm.viridis(np.linspace(0, 1, len(contagens)))
    bars = ax4.bar(range(len(contagens)), contagens, color=cores, edgecolor='black', linewidth=1.5)
    ax4.set_xlabel('Cluster', fontsize=11)
    ax4.set_ylabel('N√∫mero de M√∫sicas', fontsize=11)
    ax4.set_title('Distribui√ß√£o das M√∫sicas por Cluster', fontsize=12, fontweight='bold')
    ax4.set_xticks(range(len(contagens)))
    ax4.grid(True, alpha=0.3, axis='y')
    
    # Adicionar valores nas barras
    for bar in bars:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('clusterizacao_tecnica.png', dpi=300, bbox_inches='tight')
    print("\n[*] Visualiza√ß√µes salvas em 'clusterizacao_tecnica.png'")
    plt.show()

def main():
    """
    Pipeline principal de clusteriza√ß√£o t√©cnica.
    
    Este modelo agrupa m√∫sicas por caracter√≠sticas de produ√ß√£o e formato,
    diferente do modelo emocional que usa valence, energy e danceability.
    """
    print("="*80)
    print("CLUSTERIZA√á√ÉO T√âCNICA DE M√öSICAS DO SPOTIFY")
    print("Modelo baseado em caracter√≠sticas de produ√ß√£o musical")
    print("="*80)
    
    caminho = os.path.join(os.path.dirname(__file__), "..", "DataSet", "spotify_songs.csv")
    caminho = os.path.abspath(caminho)
    print(f"\n[*] Caminho do dataset: {caminho}")

    # Carregar dados com features t√©cnicas
    df, df_features = carregar_dados(caminho)
    features = df_features.columns.tolist()

    # Normaliza√ß√£o
    dados_normalizados, scaler = preprocessar_dados(df_features)

    # M√©todo do cotovelo
    escolher_numero_clusters(dados_normalizados, max_clusters=10)
    
    # Baseado na an√°lise do cotovelo, escolher n√∫mero de clusters
    # Para caracter√≠sticas t√©cnicas, 4 clusters costuma ser ideal:
    # 1. M√∫sicas instrumentais longas
    # 2. M√∫sicas vocais de est√∫dio
    # 3. Grava√ß√µes ao vivo
    # 4. Conte√∫do falado (rap/hip-hop)
    n_clusters = 4

    # K-Means++
    clusters, kmeans = aplicar_kmeans(dados_normalizados, n_clusters=n_clusters)

    # An√°lise e visualiza√ß√µes
    df_resultado, medias = analisar_clusters(df, df_features, clusters, kmeans, scaler)

    # Salvar resultados
    output_file = "resultados_clusterizacao_tecnica.csv"
    df_resultado.to_csv(output_file, index=False)
    print(f"\n[‚úì] Resultados salvos em '{output_file}'.")
    
    # Adicionar informa√ß√µes sobre os clusters ao arquivo
    with open("interpretacao_clusters_tecnicos.txt", "w", encoding="utf-8") as f:
        f.write("="*80 + "\n")
        f.write("INTERPRETA√á√ÉO DOS CLUSTERS - Modelo T√©cnico\n")
        f.write("="*80 + "\n\n")
        f.write("Features utilizadas:\n")
        f.write("- loudness: Volume/intensidade (dB)\n")
        f.write("- speechiness: Presen√ßa de conte√∫do falado (0-1)\n")
        f.write("- instrumentalness: N√≠vel de instrumenta√ß√£o (0-1)\n")
        f.write("- liveness: Indicador de grava√ß√£o ao vivo (0-1)\n")
        f.write("- duration_min: Dura√ß√£o em minutos\n\n")
        f.write("="*80 + "\n\n")
        f.write(medias.to_string())
        f.write("\n\n" + "="*80 + "\n")
    
    print("[‚úì] Interpreta√ß√£o dos clusters salva em 'interpretacao_clusters_tecnicos.txt'.")
    print("\n" + "="*80)
    print("CLUSTERIZA√á√ÉO CONCLU√çDA COM SUCESSO!")
    print("="*80)

if __name__ == "__main__":
    main()
