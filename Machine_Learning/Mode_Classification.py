# ============================================
# Classificador de Modalidade Musical
# Desafio Psicoac√∫stico: Maior vs. Menor
# ============================================
# Hip√≥tese: A percep√ß√£o humana de positividade (valence) est√° 
# correlacionada com a escolha te√≥rica de uma escala Maior (mode)?
# ============================================

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# ============================================
# 1. Carregar o dataset
# ============================================
print("=" * 60)
print("üéµ CLASSIFICADOR DE MODALIDADE MUSICAL (Maior vs. Menor)")
print("=" * 60)

csv_path = Path(__file__).resolve().parent.parent / 'DataSet' / 'spotify_songs.csv'
df = pd.read_csv(csv_path)

print(f"\nüìä Dataset carregado: {len(df)} m√∫sicas")
print(f"   Colunas dispon√≠veis: {len(df.columns)}")

# ============================================
# 2. An√°lise Explorat√≥ria da Vari√°vel Target
# ============================================
print("\n" + "=" * 60)
print("üìà AN√ÅLISE EXPLORAT√ìRIA DO MODE")
print("=" * 60)

mode_counts = df['mode'].value_counts()
print(f"\nDistribui√ß√£o do Mode:")
print(f"   Mode 1 (Maior): {mode_counts.get(1, 0)} ({mode_counts.get(1, 0)/len(df)*100:.2f}%)")
print(f"   Mode 0 (Menor): {mode_counts.get(0, 0)} ({mode_counts.get(0, 0)/len(df)*100:.2f}%)")

# An√°lise da correla√ß√£o entre valence e mode
print(f"\nüîç Correla√ß√£o entre Valence e Mode: {df['valence'].corr(df['mode']):.4f}")
print("\nüìä Estat√≠sticas de Valence por Mode:")
print(df.groupby('mode')['valence'].describe())

# ============================================
# 3. Selecionar features e alvo
# ============================================
print("\n" + "=" * 60)
print("üéØ PREPARA√á√ÉO DOS DADOS")
print("=" * 60)

# Features de √°udio dispon√≠veis
audio_features = [
    'danceability', 'energy', 'key', 'loudness', 'speechiness',
    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',
    'duration_ms', 'track_popularity'
]

# Remover linhas com valores faltantes nas features ou no target
df_clean = df[audio_features + ['mode']].dropna()
print(f"\n‚úì Dados limpos: {len(df_clean)} m√∫sicas (removidos {len(df) - len(df_clean)} registros com valores faltantes)")

X = df_clean[audio_features]
y = df_clean['mode']

print(f"\n‚úì Features selecionadas ({len(audio_features)}):")
for feat in audio_features:
    print(f"   ‚Ä¢ {feat}")
print(f"\n‚úì Target: mode (0 = Menor, 1 = Maior)")

# ============================================
# 4. Modelos para compara√ß√£o
# ============================================
print("\n" + "=" * 60)
print("ü§ñ CONFIGURA√á√ÉO DOS MODELOS")
print("=" * 60)

models = {
    "Logistic Regression": LogisticRegression(
        max_iter=1000, 
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    ),
    "Random Forest": RandomForestClassifier(
        n_estimators=200, 
        max_depth=20,
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    ),
    "Extra Trees": ExtraTreesClassifier(
        n_estimators=200,
        max_depth=20,
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    ),
    "KNN (k=5)": KNeighborsClassifier(
        n_neighbors=5,
        n_jobs=-1
    )
}

print(f"\n‚úì {len(models)} modelos configurados:")
for name in models.keys():
    print(f"   ‚Ä¢ {name}")

# ============================================
# 5. Valida√ß√£o Cruzada Estratificada
# ============================================
print("\n" + "=" * 60)
print("üîÑ VALIDA√á√ÉO CRUZADA (5-Fold Estratificada)")
print("=" * 60)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
results = {}

# Escalonamento dos dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("\nExecutando valida√ß√£o cruzada...")
for name, model in models.items():
    print(f"   ‚Üí Testando {name}...", end=" ")
    scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy', n_jobs=-1)
    results[name] = {
        "Acur√°cia M√©dia": np.mean(scores),
        "Desvio Padr√£o": np.std(scores),
        "Min": np.min(scores),
        "Max": np.max(scores)
    }
    print(f"‚úì {np.mean(scores):.4f} (¬±{np.std(scores):.4f})")

# ============================================
# 6. Resultados da Valida√ß√£o Cruzada
# ============================================
print("\n" + "=" * 60)
print("üìä RESULTADOS DA VALIDA√á√ÉO CRUZADA")
print("=" * 60)

results_df = pd.DataFrame(results).T.sort_values(by="Acur√°cia M√©dia", ascending=False)
print("\n" + results_df.to_string())

# ============================================
# 7. Treinar e avaliar o melhor modelo
# ============================================
melhor_modelo_nome = results_df.index[0]
melhor_acuracia = results_df.loc[melhor_modelo_nome, "Acur√°cia M√©dia"]

print("\n" + "=" * 60)
print(f"üèÜ MELHOR MODELO: {melhor_modelo_nome}")
print(f"   Acur√°cia M√©dia: {melhor_acuracia:.4f}")
print("=" * 60)

# Divis√£o treino/teste estratificada
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

print(f"\n‚úì Divis√£o dos dados:")
print(f"   Treino: {len(X_train)} amostras")
print(f"   Teste:  {len(X_test)} amostras")

# Treinar o melhor modelo
melhor_modelo = models[melhor_modelo_nome]
print(f"\nüîß Treinando {melhor_modelo_nome}...")
melhor_modelo.fit(X_train, y_train)

# Predi√ß√µes
y_pred = melhor_modelo.predict(X_test)
y_pred_proba = melhor_modelo.predict_proba(X_test)[:, 1] if hasattr(melhor_modelo, 'predict_proba') else None

# ============================================
# 8. Classification Report
# ============================================
print("\n" + "=" * 60)
print("üìã CLASSIFICATION REPORT")
print("=" * 60)
print("\nClasses: 0 = Menor (Minor), 1 = Maior (Major)\n")
print(classification_report(y_test, y_pred, target_names=['Menor (0)', 'Maior (1)'], digits=4))

# ============================================
# 9. M√©tricas Adicionais
# ============================================
print("=" * 60)
print("üìä M√âTRICAS ADICIONAIS")
print("=" * 60)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nMatriz de Confus√£o:")
print(f"                 Predito")
print(f"              Menor  Maior")
print(f"Real  Menor  {cm[0][0]:6d} {cm[0][1]:6d}")
print(f"      Maior  {cm[1][0]:6d} {cm[1][1]:6d}")

# ROC-AUC Score
if y_pred_proba is not None:
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    print(f"\nüéØ ROC-AUC Score: {roc_auc:.4f}")

# ============================================
# 10. An√°lise de Feature Importance
# ============================================
if hasattr(melhor_modelo, 'feature_importances_'):
    print("\n" + "=" * 60)
    print("üîç IMPORT√ÇNCIA DAS FEATURES")
    print("=" * 60)
    
    feature_importance = pd.DataFrame({
        'Feature': audio_features,
        'Importance': melhor_modelo.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    print("\n" + feature_importance.to_string(index=False))
    
    valence_importance = feature_importance[feature_importance['Feature'] == 'valence']['Importance'].values[0]
    valence_rank = (feature_importance['Feature'] == 'valence').idxmax() + 1
    print(f"\nüéµ Valence - Ranking: #{valence_rank} | Import√¢ncia: {valence_importance:.4f}")

elif hasattr(melhor_modelo, 'coef_'):
    print("\n" + "=" * 60)
    print("üîç COEFICIENTES DO MODELO")
    print("=" * 60)
    
    coef_df = pd.DataFrame({
        'Feature': audio_features,
        'Coefficient': melhor_modelo.coef_[0]
    }).sort_values(by='Coefficient', key=abs, ascending=False)
    
    print("\n" + coef_df.to_string(index=False))
    
    valence_coef = coef_df[coef_df['Feature'] == 'valence']['Coefficient'].values[0]
    print(f"\nüéµ Valence - Coeficiente: {valence_coef:.4f}")

# ============================================
# 11. Compara√ß√£o de TODOS os Modelos no Teste
# ============================================
print("\n" + "=" * 60)
print("üî¨ COMPARA√á√ÉO DE TODOS OS MODELOS NO CONJUNTO DE TESTE")
print("=" * 60)

test_results = []
for name, model in models.items():
    model.fit(X_train, y_train)
    test_score = model.score(X_test, y_test)
    test_results.append({'Modelo': name, 'Acur√°cia no Teste': test_score})

test_results_df = pd.DataFrame(test_results).sort_values(by='Acur√°cia no Teste', ascending=False)
print("\n" + test_results_df.to_string(index=False))

# ============================================
# 12. Conclus√£o
# ============================================
print("\n" + "=" * 60)
print("CONCLUS√ÉO")
print("=" * 60)

print(f"\nüèÜ Melhor Modelo: {melhor_modelo_nome}")
print(f"   Acur√°cia: {melhor_acuracia:.4f}")